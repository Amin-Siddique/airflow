#first create namespace where every resource related to airflow will belong:
kubectl create namespace  airflow

## create secret & traefik before to avoid pod initiation issue: edit hostname: C:\Windows\System32\drivers\etc
# apply the secret for gitSync:
kubectl apply -f secret.yaml -n airflow
# run traefik to run airflow UI on localhost
helm upgrade --install traefik traefik/traefik -f values_ingress.yaml
kubectl apply -f .\ingress_traefik.yaml

#apply persistent volume to store logs locally \\wsl.localhost\docker-desktop-data\data\k8s-pvs\airflow-pv1
kubectl apply -f .\PV.yaml  

kubectl create secret generic envvar --from-file=env_var_secret.json -n airflow
# airflow helm:
helm install airflow apache-airflow/airflow --namespace airflow --create-namespace  --debug
helm show values apache-airflow/airflow > values.yaml
helm upgrade --install airflow apache-airflow/airflow -n airflow -f values.yaml --debug

helm upgrade --install airflow apache-airflow/airflow -n airflow -f values.yaml --values override.yaml --debug


#if not traefik then run locally:
kubectl port-forward svc/airflow-webserver 8081:8080 --namespace airflow

#restart container:
kubectl rollout restart deployment airflow-scheduler -n airflow
kubectl rollout restart deployment airflow-webserver -n airflow

helm delete airflow --namespace airflow
delete  pvc airflow-pvc #delete pvc before pv
kubectl create namespace airflow
kubectl delete namespace airflow

##https://helm.sh/docs/helm/helm_get_manifest/
helm show chart apache-airflow/airflow --version 1.10.0  > chart.yaml
helm get manifest airflow -n airflow > manifest.yaml


docker logout
docker login
docker tag airflow-amin maxvan112/airflow-amin:1.1
docker push {username}/{imagename}:{versionNumber}


## get .kubeconfig file:
kubectl config view --minify --flatten
kubectl config use-context docker-desktop  #set context

kubectl delete all --all

kubectl get pv



helm install spark bitnami/spark --namespace spark --create-namespace  --debug


###### SPARK:
helm install spark oci://registry-1.docker.io/bitnamicharts/spark --namespace spark --create-namespace  -f spark/spark_values.yaml --debug
helm delete spark -n spark


helm upgrade --install spark oci://registry-1.docker.io/bitnamicharts/spark --namespace spark -f spark_values.yaml  --debug


## SSL -> Install certificate manager
#1. install (this will create cert-manager namspace)
kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml

#2. create issuer: represt CA (Cert authority) that are able to generate signed certifications
kubectl apply -f .\cert_issuer.yaml

kubectl get clusterissuer 


#3. update ingress:

kubectl get  certificaterequest -n airflow  
kubectl describe  certificaterequest -n airflow
kubectl describe order letsencrypt-jcct2-1348285117 -n airflow
kubectl describe challenge letsencrypt-jcct2-1348285117-3083901839 -n airflow
kubectl cluster-info



## git:
(i) remove tracking of a file:
git rm --cached values.yaml 
(ii) remove the previous commits (below example remove previous 10 commits in local):
git reset --hard HEAD~10
(iii) force push from local to remote in case doing hard reset:
 git push origin main --force




## Github Actions: go to folder actions-runner
./run.cmd




#### KAFKA:

helm install kafka oci://registry-1.docker.io/bitnamicharts/kafka -n kafka --create-namespace
helm upgrade --install kafka  oci://registry-1.docker.io/bitnamicharts/kafka -n kafka -f values.yaml --values override.yaml --debug

## FLINK: (NOT WOKRING)
helm install flink oci://registry-1.docker.io/bitnamicharts/flink -n flink --create-namespace
helm upgrade --install flink oci://registry-1.docker.io/bitnamicharts/flink -n flink  -f values.yaml --values override.yaml --debug

## FLINK KUBERNETES OPERATOR:  (NOT WOKRING)
kubectl create -f https://github.com/jetstack/cert-manager/releases/download/v1.8.2/cert-manager.yaml
helm repo add flink-operator-repo https://downloads.apache.org/flink/flink-kubernetes-operator-1.6.1/
helm install flink-kubernetes-operator flink-operator-repo/flink-kubernetes-operator -n flink 

## not sure:  helm upgrade --install flink-kubernetes-operator flink-operator-repo/flink-kubernetes-operator -n flink  -f values.yaml --values override.yaml --debug



##LAKEFS: https://github.com/treeverse/lakeFS-samples

helm repo add lakefs https://charts.lakefs.io
helm upgrade --install lakefs lakefs/lakefs -n lakefs --create-namespace  -f values.yaml --values override.yaml --debug

